<!-- Static publications include: reproduces thumbnail + metadata + links -->
<div class="bibliography clearfix">

  <!-- Entry: AttenNKF (2026) -->
  <div id="lee2026attention" class="col three yellow-box">
    <div style="clear: both;">
      <div>
        <img class="col bibone first" src="/assets/img/teasers/attennkf.gif" alt="AttenNKF teaser">
      </div>
    </div>
    <div class="col bibtwo last">
      <div class="title">Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation</div>
      <div class="author"><strong>Seokju Lee</strong>, Kyung-Soo Kim</div>
      <div class="periodical"><em>IEEE Robotics and Automation Letters (RA-L) (Under Review)</em></div>

      <div class="links">
        [<a class="abstract">Abs</a>]
        [<a href="" target="_blank">arXiv (Coming Soon)</a>]
        [<a href="" target="_blank">Website (Coming Soon)</a>]
      </div>

      <div class="abstract hidden">
        <p>In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation
          in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements
          violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this
          slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF)
          with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity
          and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter
          update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales
          and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments
          demonstrate improved performance compared to existing legged-robot state estimators, particularly under
          slip-prone conditions.</p>
      </div>
    </div>
  </div>

  <!-- Entry: InNKF (2025) -->
  <div id="lee2025legged" class="col three yellow-box">
    <div style="clear: both;">
      <div>
        <img class="col bibone first" src="/assets/img/teasers/innkf.gif" alt="InNKF teaser">
      </div>
    </div>
    <div class="col bibtwo last">
      <div class="title">Legged Robot State Estimation Using Invariant Neural-Augmented Kalman Filter with a Neural
        Compensator</div>
      <div class="author"><strong>Seokju Lee</strong>, Hyun-Bin Kim, Kyung-Soo Kim</div>
      <div class="periodical"><em>The 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems
          (IROS)</em></div>

      <div class="links">
        [<a class="abstract">Abs</a>]
        [<a href="http://arxiv.org/abs/2503.00344" target="_blank">arXiv</a>]
        [<a href="https://ieeexplore.ieee.org/document/11247668" target="_blank">Paper</a>]
        [<a href="https://seokju-lee.github.io/innkf_webpage/" target="_blank">Website</a>]
      </div>

      <div class="abstract hidden">
        <p>This paper presents an algorithm to improve state estimation for legged robots. Among existing model-based
          state estimation methods for legged robots, the contact-aided invariant extended Kalman filter defines the
          state on a Lie group to preserve invariance, thereby significantly accelerating convergence. It achieves more
          accurate state estimation by leveraging contact information as measurements for the update step. However, when
          the model exhibits strong nonlinearity, the estimation accuracy decreases. Such nonlinearities can cause
          initial errors to accumulate and lead to large drifts over time. To address this issue, we propose
          compensating for errors by augmenting the Kalman filter with an artificial neural network serving as a
          nonlinear function approximator. Furthermore, we design this neural network to respect the Lie group structure
          to ensure invariance, resulting in our proposed Invariant Neural-Augmented Kalman Filter (InNKF). The proposed
          algorithm offers improved state estimation performance by combining the strengths of model-based and
          learning-based approaches.</p>
      </div>
    </div>
  </div>

  <!-- Entry: PR-L (2025) -->
  <div id="jung2025text" class="col three">
    <div style="clear: both;">
      <div>
        <img class="col bibone first" src="/assets/img/teasers/PR_L.png" alt="PR-L teaser">
      </div>
    </div>
    <div class="col bibtwo last">
      <div class="title">Text optimization with latent inversion for non-rigid image editing</div>
      <div class="author">Yunji Jung, <strong>Seokju Lee</strong>, Tair Djanibekov, Jong Chul Ye, Hyunjung Shim</div>
      <div class="periodical"><em>Pattern Recognition Letters</em></div>

      <div class="links">
        [<a class="abstract">Abs</a>]
        [<a href="https://www.sciencedirect.com/science/article/pii/S0167865525002399" target="_blank">Paper</a>]
        [<a href="https://github.com/YunjiJung0105/TOLI-non-rigid-editing" target="_blank">Code</a>]
      </div>

      <div class="abstract hidden">
        <p>Text-guided non-rigid image editing involves complex edits for input images, such as changing motion or
          compositions of the object (e.g., making a horse jump or adding candles on a cake). Since it requires
          manipulating the structure of the object, existing methods often compromise “image identity”– defined as the
          overall object appearance and background details – particularly when combined with Stable Diffusion. In this
          work, we propose a new approach for non-rigid image editing with Stable Diffusion, aimed at improving the
          image identity preservation quality without compromising editability. Our approach comprises three stages:
          text optimization, latent inversion, and timestep-aware text injection sampling. Inspired by the success of
          Imagic, we employ their text optimization for smooth editing. Then, we introduce latent inversion to preserve
          the input image’s identity without additional model fine-tuning. To fully utilize the input reconstruction
          ability of latent inversion, we employ timestep-aware text injection sampling, strategically injecting the
          source text prompt in early sampling steps and then transitioning to the target prompt in subsequent sampling
          steps. This strategic approach seamlessly harmonizes with text optimization, facilitating complex non-rigid
          edits to the input without losing the original identity. We demonstrate the effectiveness of our method in
          terms of identity preservation, editability, and aesthetic quality through extensive experiments. Our code is
          available at https://github.com/YunjiJung0105/TOLI-non-rigid-editing</p>
      </div>
    </div>
  </div>


  <!-- Entry: Sensors (2025) -->
  <div id="kim2025temperature" class="col three">
    <div style="clear: both;">
      <div>
        <img class="col bibone first" src="/assets/img/teasers/sensors.png" alt="Sensors teaser">
      </div>
    </div>
    <div class="col bibtwo last">
      <div class="title">Temperature Compensation Method for a Six-Axis Force/Torque Sensor Using a Gated Recurrent Unit
      </div>
      <div class="author">Hyun-Bin Kim, <strong>Seokju Lee</strong>, Byeong-Il Ham, Keun-Ha Choi, and Kyung-Soo Kim
      </div>
      <div class="periodical"><em>IEEE Sensors Journal</em></div>

      <div class="links">
        [<a class="abstract">Abs</a>]
        [<a href="https://arxiv.org/abs/2502.17528" target="_blank">arXiv</a>]
        [<a href="https://ieeexplore.ieee.org/abstract/document/11021311" target="_blank">Paper</a>]
      </div>

      <div class="abstract hidden">
        <p>This study aims to enhance the accuracy of a six-axis force/torque (F/T) sensor by improving upon existing
          approaches that use a multilayer perceptron (MLP) and the least-squares method (LSM). While previous research
          has used MLPs for thermal compensation, it has not effectively addressed temperature-induced drift. The sensor
          used in this study operates based on infrared light and incorporates a photocoupler, which makes it highly
          sensitive to dark current effects, resulting in significant drift under temperature variations. Moreover, its
          compact and lightweight design (45 g) leads to low thermal capacity, making it susceptible to rapid
          temperature fluctuations even with minimal heat input, which in turn affects real-time performance. To address
          these challenges, this study proposes a gated recurrent unit (GRU)-based method and compares it with the
          conventional MLP approach. Experimental results demonstrate that the GRU-based model significantly reduces
          drift from 26 to 2.7 N, and the root mean square error (RMSE) from 500 to 3—representing a 100fold
          improvement. These findings suggest that GRU-based modeling substantially improves real-time F/T measurements
          in temperature-sensitive environments, benefiting applications in robotics and precision instrumentation.</p>
      </div>
    </div>
  </div>

  <!-- Entry: Legged Mobile Manipulation (2022) -->
  <div id="lee2022learning" class="col three">
    <div style="clear: both;">
      <div>
        <img class="col bibone first" src="/assets/img/teasers/mobile_manipulator.gif" alt="Mobile manipulator teaser">
      </div>
    </div>
    <div class="col bibtwo last">
      <div class="title">Learning legged mobile manipulation using reinforcement learning</div>
      <div class="author"><strong>Seokju Lee</strong>, Seunghun Jeon, Jemin Hwangbo</div>
      <div class="periodical"><em>The 2022 International Conference on Robot Intelligence Technology and Applications
          (RiTA)</em></div>

      <div class="links">
        [<a class="abstract">Abs</a>]
        [<a href="https://link.springer.com/chapter/10.1007/978-3-031-26889-2_28" target="_blank">Paper</a>]
      </div>

      <div class="abstract hidden">
        <p>Many studies on quadrupedal manipulators have been conducted for extending the workspace of the end-effector.
          Many of these studies, especially the recent ones, use model-based control for the arm and learning-based
          control for the leg. Some studies solely focused on model-based control for controlling both the base and arm.
          However, model-based controllers such as MPC can be computationally inefficient when there are many contacts
          between the end-effector and the object. The dynamics of the interactions between a quadrupedal manipulator
          and the object in contact are complex and often unpredictable without high-resolution contact sensors on the
          end-effector. In this study, we investigate the possibility of using a reinforcement learning strategy to
          control an end-effector of a legged mobile manipulator. The proposed framework is verified for a walking and
          tracking task of the end-effector in a simulation environment.</p>
      </div>
    </div>
  </div>

  <div style="clear:both;"></div>
</div>